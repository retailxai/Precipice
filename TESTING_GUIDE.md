# Testing Guide for RetailXAI Dashboard

This guide covers all testing aspects of the RetailXAI Dashboard, including backend, frontend, and E2E tests.

## ðŸ§ª Test Structure

```
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ conftest.py          # Test configuration and fixtures
â”‚   â”‚   â”œâ”€â”€ test_auth.py         # Authentication tests
â”‚   â”‚   â”œâ”€â”€ test_drafts.py       # Draft API tests
â”‚   â”‚   â””â”€â”€ test_rbac.py         # RBAC tests
â”‚   â””â”€â”€ pytest.ini              # Pytest configuration
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ setup.ts             # Test setup
â”‚   â”‚   â””â”€â”€ components/          # Component tests
â”‚   â””â”€â”€ jest.config.js           # Jest configuration
â”œâ”€â”€ e2e/
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ dashboard.spec.ts    # E2E tests
â”‚   â””â”€â”€ playwright.config.ts     # Playwright configuration
â””â”€â”€ scripts/
    â””â”€â”€ test.sh                  # Test runner script
```

## ðŸš€ Quick Start

### Run All Tests
```bash
./scripts/test.sh
```

### Run Specific Test Suites
```bash
# Backend only
./scripts/test.sh --backend-only

# Frontend only
./scripts/test.sh --frontend-only

# E2E only
./scripts/test.sh --e2e-only

# Include E2E tests
./scripts/test.sh --include-e2e
```

### Run with Verbose Output
```bash
./scripts/test.sh --verbose
```

## ðŸ”§ Backend Tests

### Setup
```bash
cd backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Run Tests
```bash
# All tests
pytest

# With coverage
pytest --cov=app --cov-report=html

# Specific test file
pytest tests/test_drafts.py

# Specific test
pytest tests/test_drafts.py::test_create_draft

# Verbose output
pytest -v
```

### Test Categories

#### Authentication Tests (`test_auth.py`)
- User registration
- Login/logout
- Token validation
- Password hashing
- User info retrieval

#### Draft API Tests (`test_drafts.py`)
- CRUD operations
- Pagination
- Search functionality
- Publishing
- Validation
- Error handling

#### RBAC Tests (`test_rbac.py`)
- Permission checking
- Role-based access
- Unauthorized access
- Token validation
- Role hierarchy

### Test Fixtures

The `conftest.py` file provides:
- `db_session`: Database session for tests
- `client`: HTTP client for API testing
- `test_user`: Editor user for testing
- `test_admin_user`: Admin user for testing
- `auth_headers`: Authentication headers
- `admin_auth_headers`: Admin authentication headers

### Database Testing

Tests use an in-memory SQLite database:
- Fast test execution
- Isolated test environment
- Automatic cleanup
- No external dependencies

## ðŸŽ¨ Frontend Tests

### Setup
```bash
cd frontend
npm install
```

### Run Tests
```bash
# All tests
npm test

# Watch mode
npm run test:watch

# Coverage
npm run test:coverage

# Specific test file
npm test -- tests/components/Dashboard.test.tsx
```

### Test Categories

#### Component Tests
- `Dashboard.test.tsx`: Main dashboard component
- `DraftCard.test.tsx`: Individual draft cards
- `DraftsList.test.tsx`: Draft list component
- `HealthCard.test.tsx`: Health monitoring
- `StatsCard.test.tsx`: Statistics display

#### Test Utilities
- Mock API responses
- User interaction simulation
- State management testing
- Error handling
- Responsive design

### Testing Library

Uses React Testing Library:
- User-centric testing
- Accessible queries
- Realistic interactions
- Component isolation

## ðŸŒ E2E Tests

### Setup
```bash
cd e2e
npm install
npx playwright install
```

### Run Tests
```bash
# All tests
npx playwright test

# Specific test
npx playwright test dashboard.spec.ts

# Headed mode (see browser)
npx playwright test --headed

# Debug mode
npx playwright test --debug
```

### Test Categories

#### Dashboard E2E Tests
- Page navigation
- Component rendering
- User interactions
- API integration
- Error handling
- Responsive design

### Browser Support
- Chromium
- Firefox
- WebKit (Safari)

### Test Environment
- Local development servers
- Mock API responses
- Isolated test data
- Automatic cleanup

## ðŸ“Š Coverage Reports

### Backend Coverage
```bash
cd backend
pytest --cov=app --cov-report=html
open htmlcov/index.html
```

### Frontend Coverage
```bash
cd frontend
npm run test:coverage
open coverage/lcov-report/index.html
```

### Coverage Targets
- **Backend**: >90% line coverage
- **Frontend**: >80% line coverage
- **Critical paths**: 100% coverage

## ðŸ” Test Data Management

### Backend Test Data
- In-memory database
- Fixture-based data
- Automatic cleanup
- Isolated test cases

### Frontend Test Data
- Mock API responses
- Component props
- User interactions
- State management

### E2E Test Data
- Mock server responses
- Test user accounts
- Sample content
- Cleanup procedures

## ðŸ› Debugging Tests

### Backend Debugging
```bash
# Run with debugger
pytest --pdb

# Print output
pytest -s

# Stop on first failure
pytest -x
```

### Frontend Debugging
```bash
# Debug mode
npm test -- --debug

# Verbose output
npm test -- --verbose

# Update snapshots
npm test -- --updateSnapshot
```

### E2E Debugging
```bash
# Debug mode
npx playwright test --debug

# Trace viewer
npx playwright show-trace trace.zip

# Screenshots
npx playwright test --screenshot=on
```

## ðŸš¨ Common Issues

### Backend Issues
1. **Database connection**: Ensure test database is properly configured
2. **Async tests**: Use `pytest-asyncio` for async test functions
3. **Fixtures**: Check fixture dependencies and scope
4. **Authentication**: Verify token generation and validation

### Frontend Issues
1. **Mock setup**: Ensure mocks are properly configured
2. **Async operations**: Use `waitFor` for async state changes
3. **Component rendering**: Check for missing dependencies
4. **API calls**: Verify mock responses match expected format

### E2E Issues
1. **Server startup**: Ensure both frontend and backend are running
2. **Timing**: Add appropriate waits for async operations
3. **Selectors**: Use stable, accessible selectors
4. **Data cleanup**: Ensure test data is properly cleaned up

## ðŸ“ˆ Performance Testing

### Backend Performance
```bash
# Load testing with pytest-benchmark
pytest --benchmark-only

# Memory profiling
pytest --profile
```

### Frontend Performance
```bash
# Bundle analysis
npm run build
npm run analyze

# Performance testing
npm run test:performance
```

## ðŸ”„ Continuous Integration

### GitHub Actions
Tests run automatically on:
- Pull requests
- Push to main branch
- Manual trigger

### Test Matrix
- Python 3.12
- Node.js 20
- Multiple browsers
- Different operating systems

## ðŸ“ Writing New Tests

### Backend Test Template
```python
@pytest.mark.asyncio
async def test_new_feature(client: AsyncClient, auth_headers):
    """Test description."""
    response = await client.post(
        "/api/endpoint",
        json={"data": "value"},
        headers=auth_headers
    )
    
    assert response.status_code == 200
    data = response.json()
    assert data["field"] == "expected_value"
```

### Frontend Test Template
```typescript
describe('ComponentName', () => {
  it('should render correctly', () => {
    render(<ComponentName prop="value" />)
    
    expect(screen.getByText('Expected Text')).toBeInTheDocument()
  })
})
```

### E2E Test Template
```typescript
test('should perform user action', async ({ page }) => {
  await page.goto('/')
  
  await page.click('button[data-testid="action-button"]')
  
  await expect(page.getByText('Success message')).toBeVisible()
})
```

## ðŸŽ¯ Best Practices

1. **Test Isolation**: Each test should be independent
2. **Clear Names**: Use descriptive test names
3. **Arrange-Act-Assert**: Structure tests clearly
4. **Mock External Dependencies**: Don't rely on external services
5. **Test Edge Cases**: Include error scenarios
6. **Keep Tests Fast**: Optimize for speed
7. **Maintain Test Data**: Keep test data up to date
8. **Document Complex Tests**: Add comments for clarity

---

**Happy Testing! ðŸ§ªâœ¨**
